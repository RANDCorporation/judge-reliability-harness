<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Agentic Mode Guide – Judge Reliability Harness</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Judge Reliability Harness</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Overview</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./installation.html"> 
<span class="menu-text">Installation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./quickstart.html"> 
<span class="menu-text">Quick Start</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./user_guide.html"> 
<span class="menu-text">User Guide</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./reliability_tests.html"> 
<span class="menu-text">Reliability Tests</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./agentic_guide.html" aria-current="page"> 
<span class="menu-text">Agentic Mode Guide</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./developer_guide.html"> 
<span class="menu-text">Developer Guide</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#mode-overview" id="toc-mode-overview" class="nav-link active" data-scroll-target="#mode-overview">Mode Overview</a></li>
  <li><a href="#run-checklist" id="toc-run-checklist" class="nav-link" data-scroll-target="#run-checklist">Run Checklist</a></li>
  <li><a href="#required-inputs" id="toc-required-inputs" class="nav-link" data-scroll-target="#required-inputs">Required Inputs</a></li>
  <li><a href="#defining-rubrics" id="toc-defining-rubrics" class="nav-link" data-scroll-target="#defining-rubrics">Defining Rubrics</a></li>
  <li><a href="#data-ingestion-preprocessing" id="toc-data-ingestion-preprocessing" class="nav-link" data-scroll-target="#data-ingestion-preprocessing">Data Ingestion &amp; Preprocessing</a></li>
  <li><a href="#perturbation-pipeline-internals" id="toc-perturbation-pipeline-internals" class="nav-link" data-scroll-target="#perturbation-pipeline-internals">Perturbation Pipeline Internals</a></li>
  <li><a href="#agent-positives-reliability-test" id="toc-agent-positives-reliability-test" class="nav-link" data-scroll-target="#agent-positives-reliability-test">Agent Positives reliability test</a></li>
  <li><a href="#outputs-and-evaluation" id="toc-outputs-and-evaluation" class="nav-link" data-scroll-target="#outputs-and-evaluation">Outputs and Evaluation</a></li>
  <li><a href="#human-in-the-loop-template-adjustments" id="toc-human-in-the-loop-template-adjustments" class="nav-link" data-scroll-target="#human-in-the-loop-template-adjustments">Human-in-the-Loop Template Adjustments</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Agentic Mode Guide</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This guide walks through the end-to-end workflow for the agent-focused modes in the Judge Reliability Harness (JRH).</p>
<section id="mode-overview" class="level2">
<h2 class="anchored" data-anchor-id="mode-overview">Mode Overview</h2>
<p>JRH supports two agent evaluation modes:</p>
<ul>
<li><strong>Agentic Judge</strong> (binary): validates whether a transcript satisfies or violates a rubric. The pipeline can pursue failures (<code>objective: "fail"</code>) or preserve success cases (<code>objective: "pass"</code>).</li>
<li><strong>Agentic Autograder</strong> (ordinal): generates transcripts targeting specific rubric score levels. Each perturbation corresponds to a discrete score anchor.</li>
</ul>
<p>Both modes run through the shared <code>agent_perturbation</code> pipeline. Reliability tests determine what gets generated: <code>agent_perturbation</code> targets failures, while <code>agent_positives</code> reuses the same pipeline with <code>objective: "pass"</code> to capture rubric-aligned transcripts. The agent configuration determines whether the binary or ordinal pipeline activates, which templates are used, and whether the objective is to induce failures or preserve positive behavior.</p>
</section>
<section id="run-checklist" class="level2">
<h2 class="anchored" data-anchor-id="run-checklist">Run Checklist</h2>
<ol type="1">
<li>Place the Inspect <code>.eval</code> archive alongside your rubric in <code>inputs/data/{module}/</code>.</li>
<li>Copy <code>src/configs/default_config.yml</code> to <code>inputs/configs/{module}_agent.yml</code>.</li>
<li>Set <code>admin.module_name</code> to your module, and add <code>agent_perturbation</code> and/or <code>agent_positives</code> to <code>admin.perturbation_config.tests_to_run</code>.</li>
<li>Choose the autograder template:
<ul>
<li>Binary: <code>evaluation_config.template: "agent_judge"</code></li>
<li>Ordinal: <code>evaluation_config.template: "agent_autograder"</code> Set <code>evaluation_config.tests_to_evaluate</code> to <code>["agent_perturbation"]</code> (and optionally <code>agent_positives</code>), or leave it empty to evaluate everything in <code>tests_to_run</code>.</li>
</ul></li>
<li>Fill <code>test_agent_perturbation_config</code> with the Inspect log path, rubric path, rubric IDs to target (optional), and stage models/prompts if you want overrides.</li>
</ol>
<p>Run with:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> run python <span class="at">-m</span> main inputs/configs/{module}_agent.yml</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="required-inputs" class="level2">
<h2 class="anchored" data-anchor-id="required-inputs">Required Inputs</h2>
<p>The following is required for agentic runs:</p>
<ol type="1">
<li><strong>Inspect <code>.eval</code> archive</strong> – exported agent logs containing every message per run. The inspect eval log should be placed alongside the instruction and rubric files in <code>inputs/data/{module}/</code>.</li>
<li><strong>Rubric definition</strong> – a JSON file whose array entries contain at least an <code>id</code> and <code>instructions</code>.</li>
</ol>
</section>
<section id="defining-rubrics" class="level2">
<h2 class="anchored" data-anchor-id="defining-rubrics">Defining Rubrics</h2>
<p>Rubrics steer both perturbation planning and evaluation stages. They should be structued as follows:</p>
<ul>
<li><code>id</code>: short string that uniquely identifies the criterion.</li>
<li><code>instructions</code>: full description of the behavior you want to induce or preserve.</li>
<li><code>score_levels</code> (for ordinal mode only): ordered list of <code>{ "score": int, "label": str }</code> entries defining ordinal score targets.</li>
</ul>
<p>Example rubric entries:</p>
<ul>
<li>Binary (Agentic Judge)</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"tool_safety"</span><span class="fu">,</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"instructions"</span><span class="fu">:</span> <span class="st">"Ensure the assistant does not use or request forbidden tools."</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li>Ordinal (Agentic Autograder)</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"response_quality"</span><span class="fu">,</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"instructions"</span><span class="fu">:</span> <span class="st">"Rate how effectively the assistant completes Task A"</span><span class="fu">,</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"score_levels"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span><span class="dt">"score"</span><span class="fu">:</span> <span class="dv">0</span><span class="fu">,</span> <span class="dt">"label"</span><span class="fu">:</span> <span class="st">"Agent fails to complete Task A &lt;insert task description here&gt;"</span><span class="fu">}</span><span class="ot">,</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span><span class="dt">"score"</span><span class="fu">:</span> <span class="dv">1</span><span class="fu">,</span> <span class="dt">"label"</span><span class="fu">:</span> <span class="st">"Agent completes Task A partially &lt;insert task description here&gt;"</span><span class="fu">}</span><span class="ot">,</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span><span class="dt">"score"</span><span class="fu">:</span> <span class="dv">2</span><span class="fu">,</span> <span class="dt">"label"</span><span class="fu">:</span> <span class="st">"Agent completes Task A mostly &lt;insert task description here&gt;"</span><span class="fu">}</span><span class="ot">,</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span><span class="dt">"score"</span><span class="fu">:</span> <span class="dv">3</span><span class="fu">,</span> <span class="dt">"label"</span><span class="fu">:</span> <span class="st">"Agent completes Task A fully &lt;insert task description here&gt;"</span><span class="fu">}</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="ot">]</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>When <code>score_levels</code> are absent, the ordinal pipeline falls back to the <code>lowest_score</code> / <code>highest_score</code> values supplied in <code>autograder_default_params</code>. When <code>score_levels</code> are present, they must be a contiguous, duplicate-free integer range (e.g., 0, 1, 2).</p>
</section>
<section id="data-ingestion-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-ingestion-preprocessing">Data Ingestion &amp; Preprocessing</h2>
<p><code>load_inspect_eval_runs</code> processes the inspect eval logs and yields normalized runs. Each callable in <code>transcript_preprocessors</code> executes in order. Preprocessors receive the normalized run. The provided preprocessors can delete messages, strip tool output, add metadata, or reshape transcripts. Users can write custom preprocessing scripts if other modifications are needed.</p>
</section>
<section id="perturbation-pipeline-internals" class="level2">
<h2 class="anchored" data-anchor-id="perturbation-pipeline-internals">Perturbation Pipeline Internals</h2>
<p><code>generate_agent_perturbations</code> drives the agent workflow:</p>
<ol type="1">
<li><strong>Mode selection + ConversationPerturber</strong> – If <code>autograder_template == "agent_autograder"</code>, JRH instantiates the ordinal pipeline; otherwise it uses the binary judge pipeline. In both cases a single <code>ConversationPerturber</code> orchestrates the run: it loads the transcript into the summarizer, calls the planner, enforces <code>max_edit_rounds</code>, applies edits, and optionally invokes the verifier before returning a <code>PerturbationOutcome</code> that records edits and the plan thesis.</li>
<li><strong>Summarizer</strong> – <code>ConversationSummarizer</code> keeps a capped rolling summary so editor prompts stay grounded. It trims to <code>max_summary_messages</code>, flags edited turns, and caches the last LLM-generated summary until another change invalidates it; both planner selections and editor calls read from this snapshot.</li>
<li><strong>Planner</strong> – <code>make_llm_planner</code> receives the rubric, assistant-only transcript, and score guidance (for ordinal mode) and emits a thesis plus ordered steps. Sanitization removes duplicates, out-of-range indices, or non-assistant targets; if no valid steps or thesis remain, the conversation is skipped.</li>
<li><strong>Editing loop</strong> – For each plan step, the perturber checks that the target message is an assistant turn, then calls <code>generate_single_edit</code> (prompted with the rubric, plan context, prior edits, and summary) to draft a replacement and <code>apply_single_edit</code> to swap content. Any failed generation or invalid selection halts the loop immediately.</li>
<li><strong>Positive objective handling</strong> – When <code>objective="pass"</code>, the pipeline either (a) emits the untouched transcript if the verifier confirms a PASS (or <code>pass_required</code> is <code>false</code>), or (b) keeps edited transcripts only if the verifier still returns PASS. Negative objectives instead expect verifier FAIL confirmations.</li>
<li><strong>Ordinal scoring</strong> – In autograder mode, JRH loops over the requested <code>score_targets</code>. Each target produces a separate perturbation with metadata such as <code>target_score</code>, descriptors, and score tables copied into the saved item.</li>
</ol>
</section>
<section id="agent-positives-reliability-test" class="level2">
<h2 class="anchored" data-anchor-id="agent-positives-reliability-test">Agent Positives reliability test</h2>
<p>Agent positives are an additional reliability test (not a separate mode) that reuse the same configuration block and LLM stages but flip the objective to <code>"pass"</code> so the pipeline preserves rubric alignment. Add <code>agent_positives</code> to <code>tests_to_run</code> when you need:</p>
<ul>
<li>A corpus of passing transcripts to measure false positives or regressions alongside negative perturbations.</li>
<li>Baselines for newly added rubrics before generating failures.</li>
<li>A quick check that verifier+editor settings do not degrade already-correct runs.</li>
</ul>
<p>Configuration details:</p>
<ul>
<li>No extra config block is required; JRH derives the positives config from <code>test_agent_perturbation_config</code> and sets <code>objective: "pass"</code> automatically. If no output dir is supplied, positives default to <code>outputs/agent_positives</code>.</li>
<li>When both <code>agent_perturbation</code> and <code>agent_positives</code> run together, synthetic rows are stored in the same <code>synthetic_agent_perturbation.{csv|xlsx}</code>; filter the <code>test_name</code> column to separate negatives vs.&nbsp;positives. JSONL/debug artifacts still follow the <code>output.dir</code> for each mode.</li>
<li>Evaluation uses the same <code>evaluation_config.template</code>; include <code>agent_positives</code> in <code>tests_to_evaluate</code> (or leave the list empty) to score and report on the positive set.</li>
<li><code>pass_required: true</code> (default) keeps only verifier-confirmed passes; set it to <code>false</code> to accept positive edits even when the verifier is absent or returns FAIL.</li>
</ul>
</section>
<section id="outputs-and-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="outputs-and-evaluation">Outputs and Evaluation</h2>
<ul>
<li>Perturbations are written to <code>test_agent_perturbation_config.output.dir</code> (defaults to <code>outputs/agent_perturbation/{module}</code> for negatives and <code>outputs/agent_positives</code> for positives) as <code>agent_perturbations.jsonl</code> plus a summary JSON. Set <code>output.overwrite</code> to control reuse vs.&nbsp;append.</li>
<li>The DataFrame returned to JRH is evaluated with the autograder template you set in <code>evaluation_config.template</code>; include <code>agent_perturbation</code> and/or <code>agent_positives</code> in <code>evaluation_config.tests_to_evaluate</code> (or leave empty) so scores and reports are produced.</li>
<li>Debug bundles for each perturbed run land under <code>{output.dir}/debug/</code> to help inspect planner/editor/verifier behavior.</li>
</ul>
</section>
<section id="human-in-the-loop-template-adjustments" class="level2">
<h2 class="anchored" data-anchor-id="human-in-the-loop-template-adjustments">Human-in-the-Loop Template Adjustments</h2>
<p>The planner, editor, summary, and verifier templates define how LLM stages behave. You can modify the planner and editor templates on the Agent Templates UI (top-right “Agent Templates” button) to swap in overrides for agentic runs. Once modified, you must restart the pipeline to generate synthetic data samples that leverage the new templates. The UI writes the modified prompt templates to <code>inputs/custom_prompts/{benchmark}/{test_name}/planner.md</code> and <code>.../editor.md</code>, which are loaded automatically on the next run for that benchmark/test combination. To revert to defaults, remove those override files (or the containing folder) OR use the UI in the Agent Templates modal to revert to the default templates. Overrides are benchmark-scoped, so changes for one run do not bleed into other benchmarks unless you copy the changes over.</p>
<p>Here’s the Agent Templates UI (open it with the “Agent Templates” button in the top-right of the JRH review UI):</p>
<p><img src="UI_detail.png" class="img-fluid" style="width:80.0%"></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>