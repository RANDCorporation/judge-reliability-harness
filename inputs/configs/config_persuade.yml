# inputs/configs/config_persuade.yml

admin:
  module_name: "persuade"
  time_stamp: null
  test_debug_mode: False

  dataset_config:
    dataset_name: "persuade_corpus_2.0_test_sample.csv"
    default_params_path:
      instruction: "persuade_instruction.txt"
      rubric: "persuade_rubric.txt"

    use_original_data_as_expected: False

    default_params:
      lowest_score: "1"
      highest_score: "6"

  perturbation_config:
    use_HITL_process: True
    tests_to_run:
      - "synthetic_ordinal"

    preprocess_columns_map:
      original_idx: "essay_id"
      request: "assignment"
      response: "full_text"
      expected: "holistic_essay_score"

  evaluation_config:
    template: "single_autograder"
    autograder_model_name: "openai/gpt-4o-mini"
    overwrite_results: False
    max_workers: 10

    tests_to_evaluate:
      - "synthetic_ordinal"

    metric: "accuracy_score"
    bootstrap_size: 0.1
    bootstrap_repetitions: 10
    get_cost_curves: False

test_stochastic_stability_config:
  sample_num_from_orig: 10
  number_of_seeds: 1
  repetitions: 1
  seed: 87

synthetic_data_params:
  generation_model_name: "openai/gpt-4o-mini"
  validation_model_name: "openai/gpt-4o-mini"
  max_tokens_generation: 1200
  max_tokens_validation: 1200

  max_workers: 10
  use_similarity_filter: False
  sample_num_from_orig: 1
  target_num_per_bucket: 1
  similarity_threshold: 0.9
  rescore_sample_size: 2
  initial_temp: 1.0
  num_seed_examples_per_generation: 1
  temp_increment: 0.1
  max_temp_cap: 1.1
  max_consecutive_failures: 2
  seed: 87
